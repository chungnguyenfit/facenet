
export PYTHONPATH=~/git/facenet/src
#export PYTHONPATH=~/nguyen_facenet/facenet/src

nohup python3 src/align/align_dataset_mtcnn.py ~/nguyen_facenet/dataset/vggface2_train/  ~/nguyen_facenet/dataset/vggface2_train_mtcnnpy_182 --image_size 182 --margin 44 > align_dataset_mtcnn.train.log 2>&1 &

nohup python -u src/train_softmax.py \
--logs_base_dir ./logs/facenet/ \
--models_base_dir ./models/facenet/ \
--data_dir ./dataset/vggface2_train_mtcnnpy_182/ \
--image_size 160 \
--model_def models.mobilenet_v2 \
--lfw_dir ./dataset/lfw_mtcnnpy_182/ \
--optimizer ADAM \
--learning_rate -1 \
--max_nrof_epochs 150 \
--keep_probability 0.8 \
--random_crop \
--random_flip \
--use_fixed_image_standardization \
--learning_rate_schedule_file data/learning_rate_schedule_classifier_vggface2.txt \
--weight_decay 5e-4 \
--embedding_size 512 \
--lfw_distance_metric 1 \
--lfw_use_flipped_images \
--lfw_subtract_mean \
--validation_set_split_ratio 0.05 \
--validate_every_n_epochs 5 \
--prelogits_norm_loss_factor 5e-4 > ../train_softmax.log 2>&1 &


nohup python -u src/train_softmax.py \
--logs_base_dir ./logs/facenet/ \
--models_base_dir ./models/facenet/ \
--data_dir ./dataset/vggface2_train_mtcnnpy_182/ \
--image_size 160 \
--model_def models.inception_resnet_v1 \
--lfw_dir ./dataset/lfw_mtcnnpy_182/ \
--optimizer ADAM \
--learning_rate -1 \
--max_nrof_epochs 150 \
--keep_probability 0.8 \
--random_crop \
--random_flip \
--use_fixed_image_standardization \
--learning_rate_schedule_file data/learning_rate_schedule_classifier_vggface2.txt \
--weight_decay 5e-4 \
--embedding_size 512 \
--lfw_distance_metric 1 \
--lfw_use_flipped_images \
--lfw_subtract_mean \
--validation_set_split_ratio 0.05 \
--validate_every_n_epochs 5 \
--prelogits_norm_loss_factor 5e-4 > ../train_softmax.inception_resnet_v1.log 2>&1 &


nohup python -u src/train_softmax.py \
--logs_base_dir ./logs/facenet/ \
--models_base_dir ./models/facenet/ \
--data_dir ./dataset/vggface2_train_mtcnnpy_182/ \
--image_size 160 \
--model_def models.squeezenet \
--batch_size 90 \
--epoch_size 1000 \
--lfw_dir ./dataset/lfw_mtcnnpy_182/ \
--learning_rate 0.1 \
--learning_rate_decay_factor 0.5 \
--learning_rate_decay_epochs 25 \
--center_loss_factor 1e-2 \
--center_loss_alfa 0.9 \
--optimizer ADAM  \
--max_nrof_epochs 2000 \
--keep_probability 0.8 \
--random_crop \
--random_flip \
--use_fixed_image_standardization \
--weight_decay 5e-5 \
--embedding_size 128 \
--lfw_distance_metric 1 \
--lfw_use_flipped_images \
--lfw_subtract_mean \
--validation_set_split_ratio 0.05 \
--validate_every_n_epochs 5 \
--prelogits_norm_loss_factor 5e-4 > ../train_softmax.squeezenet.3.log 2>&1 &

FACENET_TRAINED_MODEL_ROOT=/Users/thien/git/facenet/models/facenet/squeezenet
MODEL_VERSION=20190125-014424

MODEL_PATH=${FACENET_TRAINED_MODEL_ROOT}/${MODEL_VERSION}
MODEL_VERSION_OPTIMIZED=${MODEL_VERSION}_optimized
MODEL_VERSION_OPTIMIZED_MODIFIED4PY=${MODEL_VERSION}_optimized_modified4py
MODEL_VERSION_OPTIMIZED_MODIFIED4JS=${MODEL_VERSION}_optimized_modified4js

# STEP 1: convert from checkpoint to frozen pb
python src/freeze_graph.py ${MODEL_PATH}/${MODEL_VERSION} ${MODEL_PATH}/${MODEL_VERSION}.pb
python src/import_pb_to_tensorboard.py --model_dir ${MODEL_PATH}/${MODEL_VERSION}.pb --log_dir ${MODEL_PATH}/${MODEL_VERSION}_tensorboard

# STEP 2: Transform the $MODEL_VERSION.pb to remove unneccessary nodes, the output optimized graph is $MODEL_VERSION_OPTIMIZED.pb; This $MODEL_VERSION_OPTIMIZED.pb is used to create MODEL_VERSION_OPTIMIZED_MODIFIED4PY and MODEL_VERSION_OPTIMIZED_MODIFIED4JS
/Users/thien/git/tensorflow/bazel-bin/tensorflow/tools/graph_transforms/transform_graph --in_graph=${MODEL_PATH}/${MODEL_VERSION}.pb  --out_graph=${MODEL_PATH}/${MODEL_VERSION_OPTIMIZED}.pb --inputs='input,phase_train' --outputs='embeddings' --transforms='
  strip_unused_nodes'
  
# STEP 3.1: Create JS model: Load the frozen MODEL_VERSION_OPTIMIZED.pb in step 2 and add preprocessing step to the graph, then export the modified graph as $MODEL_VERSION_OPTIMIZED_MODIFIED4JS.pb
	//Run the python code in the pb project: pb/TrueID/src/python/biometric/biometric/gcp/imgembextraction/feature_model_4js.py 
# STEP 3.2: Convert to JS model using tensorflowjs_converter

/anaconda/envs/patsnap_env/bin/tensorflowjs_converter  \
	--input_format=tf_frozen_model \
	--output_node_names='embeddings' \
	${MODEL_PATH}/${MODEL_VERSION_OPTIMIZED_MODIFIED4JS}.pb \
	${MODEL_PATH}/${MODEL_VERSION_OPTIMIZED_MODIFIED4JS}
# STEP 3.3: Copy ${MODEL_PATH}/${MODEL_VERSION_OPTIMIZED_MODIFIED4JS} directory to pb-web project
cp -rf ${MODEL_PATH}/${MODEL_VERSION_OPTIMIZED_MODIFIED4JS}/* /Users/thien/git/pb-web/bug/face_embedding_extraction_tensorflow/

# STEP 4: Create PY model: Load the frozen MODEL_VERSION_OPTIMIZED.pb in step 2 and add preprocessing step to the graph, then export the modified graph as $MODEL_VERSION_OPTIMIZED_MODIFIED4PY.pb
	//Run the python code in the pb project: pb/TrueID/src/python/biometric/biometric/gcp/imgembextraction/feature_model.py 
	//Copy ${MODEL_PATH}/${MODEL_VERSION_OPTIMIZED_MODIFIED4PY} directory to pb project under gcp so that we can export to Google Cloud Platform

	
	
##############################################################################################

python -u src/train_softmax.py \
--logs_base_dir ./logs/facenet/ \
--models_base_dir ./models/facenet/ \
--data_dir ./dataset/vggface2_train_mtcnnpy_182/ \
--image_size 160 \
--model_def models.squeezenet \
--epoch_size 10 \
--lfw_dir ./dataset/lfw_mtcnnpy_182/ \
--learning_rate 0.1 \
--learning_rate_decay_factor 0.5 \
--learning_rate_decay_epochs 25 \
--center_loss_factor 1e-2 \
--center_loss_alfa 0.9 \
--optimizer ADAM  \
--max_nrof_epochs 2000 \
--keep_probability 0.8 \
--random_crop \
--random_flip \
--use_fixed_image_standardization \
--weight_decay 5e-5 \
--embedding_size 512 \
--lfw_distance_metric 1 \
--lfw_use_flipped_images \
--lfw_subtract_mean \
--validation_set_split_ratio 0.05 \
--validate_every_n_epochs 5 \
--prelogits_norm_loss_factor 5e-4
    
python -u src/train_softmax.py \
--logs_base_dir ./logs/facenet/ \
--models_base_dir ./models/facenet/ \
--data_dir ./dataset/vggface2_test_mtcnnpy_182/ \
--image_size 160 \
--model_def models.squeezenet \
--epoch_size 5 \
--learning_rate 0.1 \
--learning_rate_decay_factor 0.5 \
--learning_rate_decay_epochs 25 \
--center_loss_factor 1e-2 \
--center_loss_alfa 0.9 \
--optimizer ADAM  \
--max_nrof_epochs 2000 \
--keep_probability 0.8 \
--random_crop \
--random_flip \
--use_fixed_image_standardization \
--weight_decay 5e-5 \
--embedding_size 512 \
--validation_set_split_ratio 0.05 \
--validate_every_n_epochs 5 \
--prelogits_norm_loss_factor 5e-4
